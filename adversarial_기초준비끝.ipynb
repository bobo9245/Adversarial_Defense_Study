{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 IMPORT\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 줄수 제한 없애기\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device 및 기본 설정 + 데이터셋 받아오기(MNIST)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=10\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/MNIST',train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='data/MNIST',train=False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(),'type:',X_train.type())\n",
    "    print('y_train:',y_train.size(), 'type:',y_train.type())\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize)) #10개 plot하기 위한 figure 크기 설정\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1) # plot.subplot(rows, columns, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 4층구조 - Conv - Relu - Pooling 4층\n",
    "class Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.gelu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.gelu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        \n",
    "        x = F.gelu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.gelu(self.bn_fc2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model,optimizer,criterion 설정\n",
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.5)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train(model, device, train_loader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM Attack Function\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "#FGSM(TSNE 시각화용)\n",
    "def fgsm_attack_2(model, image, label, epsilon, criterion):\n",
    "    # FGSM attack implementation\n",
    "    image.requires_grad = True\n",
    "    output = model(image)\n",
    "    loss = criterion(output, label)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = image.grad.data\n",
    "    perturbed_image = image + epsilon * data_grad.sign()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "# PGD Attack Function\n",
    "def pgd_attack(model, image, label, epsilon, alpha, attack_iters, criterion):\n",
    "    perturbed_image = image.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    original_image = image.clone().detach()\n",
    "    \n",
    "    for _ in range(attack_iters):\n",
    "        output = model(perturbed_image)\n",
    "        loss = criterion(output, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = perturbed_image.grad.data\n",
    "        \n",
    "        perturbed_image = perturbed_image + alpha * data_grad.sign()\n",
    "        perturbation = torch.clamp(perturbed_image - original_image, min=-epsilon, max=epsilon)\n",
    "        perturbed_image = torch.clamp(original_image + perturbation, 0, 1).detach_().requires_grad_(True)\n",
    "    \n",
    "    return perturbed_image\n",
    "\n",
    "# Adversarial Training with FGSM\n",
    "def train_with_fgsm(model, device, train_loader, optimizer, criterion, epochs, epsilon):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data.requires_grad = True\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            data_grad = data.grad.data\n",
    "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "            \n",
    "            output = model(perturbed_data)\n",
    "            loss_adv = criterion(output, target)\n",
    "            loss_adv.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() + loss_adv.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} with FGSM Attack, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Adversarial Training with PGD\n",
    "def train_with_pgd(model, device, train_loader, optimizer, criterion, epochs, epsilon, alpha, attack_iters):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            perturbed_data = pgd_attack(model, data, target, epsilon, alpha, attack_iters, criterion)\n",
    "            output = model(perturbed_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} with PGD Attack, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Evaluation Function\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(prediction.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(original_images_list, perturbed_images_list, original_labels_list, perturbed_preds_list, num_images=16):\n",
    "    \"\"\"\n",
    "    Visualizes original and adversarial images side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    - original_images_list: List of tensors containing original images.\n",
    "    - perturbed_images_list: List of tensors containing adversarial images.\n",
    "    - original_labels_list: List of original labels.\n",
    "    - perturbed_preds_list: List of adversarial predictions.\n",
    "    - num_images: Number of image pairs to visualize.\n",
    "    \"\"\"\n",
    "    # Concatenate all batches into a single tensor and ensure they are detached\n",
    "    original_images = torch.cat(original_images_list, dim=0)[:num_images].detach()\n",
    "    perturbed_images = torch.cat(perturbed_images_list, dim=0)[:num_images].detach()\n",
    "    original_labels = np.concatenate(original_labels_list, axis=0)[:num_images]\n",
    "    perturbed_preds = np.concatenate(perturbed_preds_list, axis=0)[:num_images]\n",
    "    \n",
    "    # Calculate the number of rows needed\n",
    "    num_cols = 8  # Number of images per row\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols  # Calculate rows needed to display all images\n",
    "\n",
    "    fig, axes = plt.subplots(2 * num_rows, num_cols, figsize=(2 * num_cols, 4 * num_rows))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        row = (i // num_cols) * 2  # Determine the row index (original and adversarial)\n",
    "        col = i % num_cols  # Determine the column index\n",
    "        \n",
    "        # Original Image\n",
    "        axes[row, col].imshow(original_images[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "        axes[row, col].set_title(f\"Original: {original_labels[i]}\")\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # Adversarial Image\n",
    "        axes[row + 1, col].imshow(perturbed_images[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "        axes[row + 1, col].set_title(f\"Adversarial: {perturbed_preds[i]}\")\n",
    "        axes[row + 1, col].axis('off')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_images, num_cols * num_rows):\n",
    "        row = (i // num_cols) * 2\n",
    "        col = i % num_cols\n",
    "        axes[row, col].axis('off')\n",
    "        axes[row + 1, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tsne(model, test_loader, epsilon, alpha, iterations, visualize=True, num_images=1000, mode='FGSM'):\n",
    "    model.eval()\n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if i * len(images) >= num_images:\n",
    "            break\n",
    "\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Apply attack based on mode\n",
    "        if mode == 'FGSM':\n",
    "            perturbed_images = fgsm_attack_2(model, images, labels, epsilon, criterion)\n",
    "        elif mode == 'PGD':\n",
    "            perturbed_images = pgd_attack(model, images, labels, epsilon, alpha, iterations, criterion)\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be either 'FGSM' or 'PGD'\")\n",
    "\n",
    "        # Collect original and perturbed images for TSNE\n",
    "        with torch.no_grad():\n",
    "            images_list.append(images)\n",
    "            labels_list.append(labels)\n",
    "            images_list.append(perturbed_images)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    # Stack all images and labels\n",
    "    images_list = torch.cat(images_list, dim=0)\n",
    "    labels_list = torch.cat(labels_list, dim=0).cpu().numpy()  # Move to CPU and convert to numpy\n",
    "\n",
    "    # Pass images through the model to get the features\n",
    "    with torch.no_grad():\n",
    "        features = model(images_list).view(images_list.size(0), -1)\n",
    "\n",
    "    # Apply TSNE to reduce to 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(features.cpu().numpy())\n",
    "\n",
    "    # Plot the TSNE visualization\n",
    "    if visualize:\n",
    "        # Colors and markers for each class (0-9)\n",
    "        colors = cm.get_cmap('tab10', 10)  # Using a colormap with 10 colors\n",
    "        markers = ['o', 's', 'v', '^', '<', '>', 'P', '*', 'X', 'D']  # Different markers for diversity\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        for class_idx in range(10):\n",
    "            # Plot original images\n",
    "            class_mask = (labels_list[:len(images_list)//2] == class_idx)\n",
    "            plt.scatter(tsne_features[:len(images_list)//2, 0][class_mask], \n",
    "                        tsne_features[:len(images_list)//2, 1][class_mask], \n",
    "                        color=colors(class_idx), marker=markers[class_idx], label=f'Original {class_idx}', alpha=0.5)\n",
    "            \n",
    "            # Plot perturbed images\n",
    "            class_mask = (labels_list[len(images_list)//2:] == class_idx)\n",
    "            plt.scatter(tsne_features[len(images_list)//2:, 0][class_mask], \n",
    "                        tsne_features[len(images_list)//2:, 1][class_mask], \n",
    "                        color=colors(class_idx), marker=markers[class_idx], label=f'Perturbed {class_idx}', edgecolor='k', alpha=0.5)\n",
    "        \n",
    "        # Set the legend to appear in the top right and split into 2 columns\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), ncol=2)\n",
    "        plt.title(f'TSNE Visualization - {mode} Attack')\n",
    "        plt.show()\n",
    "\n",
    "    return tsne_features, labels_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with FGSM Attack\n",
    "def evaluate_with_fgsm_attack(model, test_loader, criterion, epsilon, visualize=True, num_images=5):\n",
    "    model.eval()\n",
    "    clean_loss, adv_loss = 0, 0\n",
    "    clean_correct, adv_correct = 0, 0\n",
    "    clean_labels, clean_preds = [], []\n",
    "    adv_labels, adv_preds = [], []\n",
    "    \n",
    "    # For Visualization\n",
    "    original_images_list = []\n",
    "    perturbed_images_list = []\n",
    "    original_labels_list = []\n",
    "    perturbed_preds_list = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # Clean Evaluation\n",
    "        output = model(data)\n",
    "        clean_loss += criterion(output, target).item()\n",
    "        clean_pred = output.max(1, keepdim=True)[1]\n",
    "        clean_correct += clean_pred.eq(target.view_as(clean_pred)).sum().item()\n",
    "        \n",
    "        clean_labels.extend(target.cpu().numpy())\n",
    "        clean_preds.extend(clean_pred.cpu().numpy())\n",
    "        \n",
    "        # FGSM Attack\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        \n",
    "        # Adversarial Evaluation\n",
    "        output = model(perturbed_data)\n",
    "        adv_loss += criterion(output, target).item()\n",
    "        adv_pred = output.max(1, keepdim=True)[1]\n",
    "        adv_correct += adv_pred.eq(target.view_as(adv_pred)).sum().item()\n",
    "        \n",
    "        adv_labels.extend(target.cpu().numpy())\n",
    "        adv_preds.extend(adv_pred.cpu().numpy())\n",
    "        \n",
    "        # Save for Visualization\n",
    "        if visualize and len(original_images_list) < num_images:\n",
    "            # Detach tensors to prevent them from tracking gradients\n",
    "            original_images_list.append(data.cpu().detach())\n",
    "            perturbed_images_list.append(perturbed_data.cpu().detach())\n",
    "            original_labels_list.append(target.cpu().numpy())\n",
    "            perturbed_preds_list.append(adv_pred.cpu().numpy())\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    clean_loss /= len(test_loader)\n",
    "    adv_loss /= len(test_loader)\n",
    "    clean_accuracy = 100. * clean_correct / len(test_loader.dataset)\n",
    "    adv_accuracy = 100. * adv_correct / len(test_loader.dataset)\n",
    "    \n",
    "    clean_f1 = f1_score(clean_labels, clean_preds, average='macro')\n",
    "    adv_f1 = f1_score(adv_labels, adv_preds, average='macro')\n",
    "    \n",
    "    clean_cm = confusion_matrix(clean_labels, clean_preds)\n",
    "    adv_cm = confusion_matrix(adv_labels, adv_preds)\n",
    "    \n",
    "    print(f\"Adversarial Test Loss: {adv_loss:.4f}, Adversarial Accuracy: {adv_accuracy:.2f}%\")\n",
    "    print(f\"Adversarial F1 Score (Macro): {adv_f1:.4f}\")\n",
    "    print(\"Adversarial Confusion Matrix:\")\n",
    "    print(adv_cm)\n",
    "    print(len(original_images_list))\n",
    "    return original_images_list,perturbed_images_list,original_labels_list,perturbed_preds_list\n",
    "    # Visualization\n",
    "    if visualize and original_images_list and perturbed_images_list:\n",
    "        visualize_comparison(original_images_list, perturbed_images_list, original_labels_list, perturbed_preds_list, num_images=num_images)\n",
    "\n",
    "# Evaluation with PGD Attack\n",
    "def evaluate_with_pgd_attack(model, test_loader, criterion, epsilon, alpha, attack_iters, visualize=True, num_images=5):\n",
    "    model.eval()\n",
    "    clean_loss, adv_loss = 0, 0\n",
    "    clean_correct, adv_correct = 0, 0\n",
    "    clean_labels, clean_preds = [], []\n",
    "    adv_labels, adv_preds = [], []\n",
    "    \n",
    "    # For Visualization\n",
    "    original_images_list = []\n",
    "    perturbed_images_list = []\n",
    "    original_labels_list = []\n",
    "    perturbed_preds_list = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # Clean Evaluation\n",
    "        output = model(data)\n",
    "        clean_loss += criterion(output, target).item()\n",
    "        clean_pred = output.max(1, keepdim=True)[1]\n",
    "        clean_correct += clean_pred.eq(target.view_as(clean_pred)).sum().item()\n",
    "        \n",
    "        clean_labels.extend(target.cpu().numpy())\n",
    "        clean_preds.extend(clean_pred.cpu().numpy())\n",
    "        \n",
    "        # PGD Attack\n",
    "        perturbed_data = pgd_attack(model, data, target, epsilon, alpha, attack_iters, criterion)\n",
    "        \n",
    "        # Adversarial Evaluation\n",
    "        output = model(perturbed_data)\n",
    "        adv_loss += criterion(output, target).item()\n",
    "        adv_pred = output.max(1, keepdim=True)[1]\n",
    "        adv_correct += adv_pred.eq(target.view_as(adv_pred)).sum().item()\n",
    "        \n",
    "        adv_labels.extend(target.cpu().numpy())\n",
    "        adv_preds.extend(adv_pred.cpu().numpy())\n",
    "        \n",
    "        # Save for Visualization\n",
    "        if visualize and len(original_images_list) < num_images:\n",
    "            original_images_list.append(data.cpu())\n",
    "            perturbed_images_list.append(perturbed_data.cpu())\n",
    "            original_labels_list.append(target.cpu().numpy())\n",
    "            perturbed_preds_list.append(adv_pred.cpu().numpy())\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    clean_loss /= len(test_loader)\n",
    "    adv_loss /= len(test_loader)\n",
    "    clean_accuracy = 100. * clean_correct / len(test_loader.dataset)\n",
    "    adv_accuracy = 100. * adv_correct / len(test_loader.dataset)\n",
    "    \n",
    "    clean_f1 = f1_score(clean_labels, clean_preds, average='macro')\n",
    "    adv_f1 = f1_score(adv_labels, adv_preds, average='macro')\n",
    "    \n",
    "    clean_cm = confusion_matrix(clean_labels, clean_preds)\n",
    "    adv_cm = confusion_matrix(adv_labels, adv_preds)\n",
    "    \n",
    "    # Print Results\n",
    "    print(f\"Adversarial Test Loss (PGD): {adv_loss:.4f}, Adversarial Accuracy (PGD): {adv_accuracy:.2f}%\")\n",
    "    print(f\"Adversarial F1 Score (Macro, PGD): {adv_f1:.4f}\")\n",
    "    print(\"Adversarial Confusion Matrix (PGD):\")\n",
    "    print(adv_cm)\n",
    "    return original_images_list, perturbed_images_list, original_labels_list,perturbed_preds_list\n",
    "    # Visualization\n",
    "    if visualize and original_images_list and perturbed_images_list:\n",
    "        visualize_comparison(original_images_list, perturbed_images_list, original_labels_list, perturbed_preds_list, num_images=num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련시의 파라미터\n",
    "epsilon=0.2\n",
    "alpha=0.1\n",
    "iterations=20\n",
    "\n",
    "### Basic Training Execution\n",
    "### Uncomment to perform basic training without adversarial attacks\n",
    "train(model, DEVICE, train_loader, optimizer, criterion, EPOCHS)\n",
    "\n",
    "# Adversarial Training Execution\n",
    "\n",
    "### FGSM Adversarial Training\n",
    "### Uncomment the following line to perform FGSM adversarial training\n",
    "# train_with_fgsm(model, DEVICE, train_loader, optimizer, criterion, EPOCHS, epsilon)\n",
    "\n",
    "### PGD Adversarial Training\n",
    "### print(\"Starting PGD Adversarial Training...\")\n",
    "# train_with_pgd(model, DEVICE, train_loader, optimizer, criterion, EPOCHS, epsilon, alpha, iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 함수들 모으 \n",
    "\n",
    "#공격시의 파라미터 설정\n",
    "epsilon=0.1\n",
    "alpha=0.1\n",
    "iterations=30\n",
    "# Evaluate on clean test data\n",
    "print(\"\\n--- Evaluating on Clean Test Data ---\")\n",
    "evaluate(model, test_loader, criterion)\n",
    "\n",
    "# Evaluate with FGSM Attack\n",
    "print(\"\\n--- Evaluating with FGSM Attack ---\")\n",
    "fgsm_original_images,fgsm_perturbed_images,fgsm_origial_labels,fgsm_perturbed_labels=evaluate_with_fgsm_attack(model, test_loader, criterion, epsilon, visualize=True, num_images=5)\n",
    "\n",
    "# Evaluate with PGD Attack\n",
    "print(\"\\n--- Evaluating with PGD Attack ---\")\n",
    "pgd_original_images,pgd_perturbed_images,pgd_origial_labels,pgd_perturbed_labels=evaluate_with_pgd_attack(model, test_loader, criterion, epsilon, alpha, iterations, visualize=True, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize 함수\n",
    "\n",
    "\n",
    "visualize_comparison(fgsm_original_images,fgsm_perturbed_images,fgsm_origial_labels,fgsm_perturbed_labels, num_images=5)\n",
    "\n",
    "visualize_comparison(pgd_original_images,pgd_perturbed_images,pgd_origial_labels,pgd_perturbed_labels, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM 기반 시각화\n",
    "tsne_features, labels = visualize_tsne(\n",
    "    model=model, \n",
    "    test_loader=test_loader, \n",
    "    epsilon=epsilon, \n",
    "    alpha=alpha, \n",
    "    iterations=iterations, \n",
    "    visualize=True, \n",
    "    num_images=2000, \n",
    "    mode='PGD'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
