{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리: 이미지를 Tensor로 변환하고 -1에서 1 사이로 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "train_dataset = datasets.MNIST(root='./data/MNIST', train=True, transform=transform, download=True)\n",
    "test_dataset  = datasets.MNIST(root='./data/MNIST', train=False, transform=transform, download=True)\n",
    "\n",
    "# 데이터로더 생성\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(z.size(0), *self.img_shape)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape=(1, 28, 28)):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)\n",
    "epochs = 20\n",
    "\n",
    "# 모델 초기화\n",
    "generator = Generator(latent_dim, img_shape)\n",
    "discriminator = Discriminator(img_shape)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# 손실 함수\n",
    "adversarial_loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] [D loss: 0.0595] [G loss: 13.3947]\n",
      "[Epoch 2/20] [D loss: 0.1270] [G loss: 5.0579]\n",
      "[Epoch 3/20] [D loss: 0.0320] [G loss: 7.9775]\n",
      "[Epoch 4/20] [D loss: 0.1080] [G loss: 7.7511]\n",
      "[Epoch 5/20] [D loss: 0.0454] [G loss: 3.2488]\n",
      "[Epoch 6/20] [D loss: 0.1369] [G loss: 7.2370]\n",
      "[Epoch 7/20] [D loss: 0.0174] [G loss: 4.7582]\n",
      "[Epoch 8/20] [D loss: 0.0194] [G loss: 4.9820]\n",
      "[Epoch 9/20] [D loss: 0.2093] [G loss: 2.9495]\n",
      "[Epoch 10/20] [D loss: 0.1837] [G loss: 2.8370]\n",
      "[Epoch 11/20] [D loss: 0.1959] [G loss: 3.8184]\n",
      "[Epoch 12/20] [D loss: 0.1942] [G loss: 4.1508]\n",
      "[Epoch 13/20] [D loss: 0.1178] [G loss: 3.9519]\n",
      "[Epoch 14/20] [D loss: 0.1666] [G loss: 3.4920]\n",
      "[Epoch 15/20] [D loss: 0.1901] [G loss: 3.3334]\n",
      "[Epoch 16/20] [D loss: 0.0928] [G loss: 4.1976]\n",
      "[Epoch 17/20] [D loss: 0.1269] [G loss: 4.3422]\n",
      "[Epoch 18/20] [D loss: 0.2426] [G loss: 2.4488]\n",
      "[Epoch 19/20] [D loss: 0.1544] [G loss: 2.9857]\n",
      "[Epoch 20/20] [D loss: 0.1458] [G loss: 3.7974]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "        batch_size = imgs.size(0)\n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "\n",
    "        real_imgs = imgs\n",
    "\n",
    "        # Generator 학습\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Discriminator 학습\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{epochs}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),  # 출력: (32, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                        # 출력: (32, 14, 14)\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1), # 출력: (64, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                        # 출력: (64, 7, 7)\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Accuracy: 98.52%\n",
      "Epoch [2/5], Accuracy: 98.79%\n",
      "Epoch [3/5], Accuracy: 98.72%\n",
      "Epoch [4/5], Accuracy: 98.63%\n",
      "Epoch [5/5], Accuracy: 99.11%\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_C = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train()\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        optimizer_C.zero_grad()\n",
    "        outputs = classifier(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_C.step()\n",
    "\n",
    "    # 테스트 셋에서 정확도 평가\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            outputs = classifier(imgs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_images = images + epsilon * images.grad.sign()\n",
    "    perturbed_images = torch.clamp(perturbed_images, -1, 1)\n",
    "    return perturbed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(generator, images, latent_dim, num_iterations=10, lr=0.01):\n",
    "    device = images.device  # Ensure z is on the same device as images\n",
    "    z = torch.randn(images.size(0), latent_dim, device=device, requires_grad=True)\n",
    "    optimizer = optim.Adam([z], lr=lr)\n",
    "\n",
    "    generator.eval()\n",
    "    for param in generator.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        gen_imgs = generator(z)\n",
    "        loss = ((gen_imgs - images) ** 2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Removed z = z.detach().requires_grad_()\n",
    "\n",
    "    reconstructed_images = generator(z.detach())\n",
    "    return reconstructed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test images: 99.11%\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        outputs = classifier(imgs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy on original test images: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial images without defense: 69.18%\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.3  # 공격 강도 설정\n",
    "\n",
    "classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for imgs, labels in test_loader:\n",
    "    adv_imgs = fgsm_attack(classifier, imgs, labels, epsilon)\n",
    "    outputs = classifier(adv_imgs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy on adversarial images without defense: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      5\u001b[0m     adv_imgs \u001b[38;5;241m=\u001b[39m fgsm_attack(classifier, imgs, labels, epsilon)\n\u001b[1;32m----> 6\u001b[0m     recon_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m classifier(recon_imgs)\n\u001b[0;32m      8\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 9\u001b[0m, in \u001b[0;36mreconstruct\u001b[1;34m(generator, images, latent_dim, num_iterations, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m gen_imgs \u001b[38;5;241m=\u001b[39m generator(z)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m ((gen_imgs \u001b[38;5;241m-\u001b[39m images) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for imgs, labels in test_loader:\n",
    "    adv_imgs = fgsm_attack(classifier, imgs, labels, epsilon)\n",
    "    recon_imgs = reconstruct(generator, adv_imgs, latent_dim)\n",
    "    outputs = classifier(recon_imgs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy on adversarial images with Defense-GAN: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 혼동 행렬 계산 함수\n",
    "def get_confusion_matrix(model, data_loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return cm\n",
    "\n",
    "# 원본 이미지에 대한 혼동 행렬\n",
    "cm_original = get_confusion_matrix(classifier, test_loader)\n",
    "# 공격된 이미지에 대한 혼동 행렬\n",
    "cm_adv = get_confusion_matrix(classifier, [(fgsm_attack(classifier, imgs, labels, epsilon), labels) for imgs, labels in test_loader])\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(cm_original, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix - Original Images')\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(cm_adv, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix - Adversarial Images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perturbation_norms(original_images, adversarial_images, reconstructed_images):\n",
    "    # 이미지를 벡터 형태로 변환\n",
    "    original_images = original_images.view(original_images.size(0), -1)\n",
    "    adversarial_images = adversarial_images.view(adversarial_images.size(0), -1)\n",
    "    reconstructed_images = reconstructed_images.view(reconstructed_images.size(0), -1)\n",
    "    \n",
    "    # 노이즈 계산\n",
    "    perturbation = adversarial_images - original_images\n",
    "    reconstructed_perturbation = reconstructed_images - original_images\n",
    "    perturbation_norms = perturbation.norm(p=2, dim=1).mean().item()\n",
    "    reconstructed_norms = reconstructed_perturbation.norm(p=2, dim=1).mean().item()\n",
    "    return perturbation_norms, reconstructed_norms\n",
    "\n",
    "# 테스트 데이터에서 샘플 이미지 가져오기\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# FGSM 공격 생성\n",
    "epsilon = 0.3\n",
    "adv_images = fgsm_attack(classifier, images, labels, epsilon)\n",
    "\n",
    "# Defense-GAN을 사용하여 이미지 복원\n",
    "recon_images = reconstruct(generator, adv_images, latent_dim)\n",
    "\n",
    "# L2 Norm 계산\n",
    "pert_norm, recon_norm = compute_perturbation_norms(images, adv_images, recon_images)\n",
    "print(f\"Average L2 norm of adversarial perturbations: {pert_norm:.4f}\")\n",
    "print(f\"Average L2 norm after Defense-GAN reconstruction: {recon_norm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 공격 강도 목록 정의\n",
    "epsilons = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "acc_without_defense = []\n",
    "acc_with_defense = []\n",
    "\n",
    "classifier.eval()\n",
    "for epsilon in epsilons:\n",
    "    # Defense-GAN 없이 정확도 측정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in test_loader:\n",
    "        adv_imgs = fgsm_attack(classifier, imgs, labels, epsilon)\n",
    "        outputs = classifier(adv_imgs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    acc_without_defense.append(accuracy)\n",
    "    print(f\"Epsilon: {epsilon}\\tAccuracy without defense: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Defense-GAN 적용 후 정확도 측정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in test_loader:\n",
    "        adv_imgs = fgsm_attack(classifier, imgs, labels, epsilon)\n",
    "        recon_imgs = reconstruct(generator, adv_imgs, latent_dim)\n",
    "        outputs = classifier(recon_imgs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    acc_with_defense.append(accuracy)\n",
    "    print(f\"Epsilon: {epsilon}\\tAccuracy with defense: {accuracy:.2f}%\")\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epsilons, acc_without_defense, marker='o', label='Without Defense')\n",
    "plt.plot(epsilons, acc_with_defense, marker='x', label='With Defense-GAN')\n",
    "plt.title('Accuracy vs Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
